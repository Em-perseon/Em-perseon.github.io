
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>DB-GPT Empowering Database Interactions with Private Large Language Models | XuSibo&#39;s Blog</title>
    <meta name="author" content="Rick" />
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/avatar.jpg" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>


<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/KaTeX/0.16.9/katex.min.css" />
<script src="/js/lib/math.js"></script>


<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>XUSIBO&#39;S BLOG</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;XUSIBO&#39;S BLOG</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div class="article">
    <div>
        <h1>DB-GPT Empowering Database Interactions with Private Large Language Models</h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2024/7/14
        </span>
        
        
        <span class="tags">
            <span class="icon">
                <i class="fa-solid fa-tags fa-fw"></i>
            </span>
            
            
            <span class="tag">
                
                <a href="/tags/LLMs-SQL/" style="color: #03a9f4">
                    LLMs SQL
                </a>
            </span>
            
        </span>
        
    </div>
    
    <div class="content" v-pre>
        <p>[TOC]</p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文研发了一个DB-GPT，它将llm与传统数据库系统集成在一起，以增强用户体验和可访问性。DB-GPT旨在<strong>理解自然语言查询</strong>，<strong>提供上下文感知响应</strong>，并以<strong>高精度生成复杂的SQL查询</strong>，使其成为从新手到专家的用户不可或缺的工具。DB-GPT的核心创新在于其私有LLMs技术，该技术对特定领域的语料库进行了<strong>微调</strong>，以维护用户隐私并确保数据安全，同时提供最先进的LLMs的优势。</p>
<p>DB-GPT的体系结构：</p>
<ul>
<li>一种新颖的<strong>检索增强生成(RAG)知识系统</strong></li>
<li>一种基于用户反馈不断提高性能的自适应学习机制</li>
<li>一种具有强大数据驱动代理的面向服务的多模型框架(SMMF)</li>
</ul>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2312.17449">https://arxiv.org/pdf/2312.17449</a></p>
<p>论文代码：<a target="_blank" rel="noopener" href="https://github.com/eosphoros-ai/DB-GPT">https://github.com/eosphoros-ai/DB-GPT</a></p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul>
<li><p>如何使用llm授权数据库操作来构建强大的最终用户应用程序仍然是一个悬而未决的问题</p>
<ul>
<li>大多数现有作品采用了一种直接的方法——直接向常用的llm(如GPT-4)提供如何通过少量简短提示或上下文学习进行交互的说明<ul>
<li>优点：它不太可能过度拟合训练数据，并且易于适应新数据</li>
<li>缺点：与中等规模llm的微调替代方案相比，性能可能不是最优的</li>
</ul>
</li>
<li>此外，还有就是将llm驱动的自动推理和决策过程(又名代理)纳入数据库应用程序中。<ul>
<li>然而，知识代理通常是特定于任务的，而不是任务不可知的，这限制了它们的使用范围。</li>
<li>同时，虽然很重要，但对以llm为中心的数据库交互的隐私敏感设置的研究还不够。</li>
</ul>
</li>
</ul>
</li>
<li><p>本工作：研究出一个DB-GPT，用于llm增强应用程序的智能和生产就绪项目，可以使用私有化技术摄取、构建和访问数据。DB-GPT不仅利用llm固有的自然语言理解和生成能力，还通过代理和插件机制不断优化数据驱动引擎。</p>
</li>
<li><p>DB-GPT具有以下明显的<strong>优点</strong>:</p>
<ul>
<li>隐私和安全保护：DB-GPT允许用户<strong>部署在个人设备或本地服务器上</strong>，即使在没有Internet连接的场景下也可以运行。任何时候都不会有数据离开执行环境，完全消除了数据泄漏的风险。此外，代理去识别技术应用于数据处理模块，它作为中介，从数据集中模糊个人标识符，从而降低未经授权访问和利用私人信息的风险。</li>
<li><strong>多源知识库问答优化：</strong>DB-GPT构建了一个管道，将<strong>多源非结构化数据(PDF，网页，图像等)提取为中间表示</strong>，将其存储在结构化知识库中，检索最相关的部分，并在给定查询时生成全面的自然语言响应。该管道进行了效率优化，生成灵活，并接受双语查询。</li>
<li>文本到sql的微调：DB-GPT对<strong>几种常用的llm进行了微调</strong>，用于Text-toSQL任务。DB-GPT在与数据交互时显著降低了不需要SQL专业知识的用户的障碍。</li>
<li><strong>集成知识代理和插件：</strong>“代理”是一个自动推理和决策引擎。作为一个生产就绪的项目，DB-GPT支持具有高级数据分析的会话代理的开发和应用，其中这些自动化决策有助于数据上的交互式用例。它还提供了各种查询和检索服务插件，用作与数据交互的工具。</li>
</ul>
<h1 id="2-系统设计"><a href="#2-系统设计" class="headerlink" title="2 系统设计"></a>2 系统设计</h1><p>系统如下图所示：</p>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714153640078.png" class="" title="image-20240714153640078">
</li>
</ul>
<h2 id="2-1-用于QA的多源RAG（Retrieval-augmented-Generation）"><a href="#2-1-用于QA的多源RAG（Retrieval-augmented-Generation）" class="headerlink" title="2.1 用于QA的多源RAG（Retrieval-augmented Generation）"></a>2.1 用于QA的多源RAG（Retrieval-augmented Generation）</h2><p>构建一个多源知识库问答，它能够理解自然语言查询，提供上下文感知的回答，并且能够生成复杂且准确的SQL查询，从而提高从新手到专家各个层面用户的数据库交互体验。如图2所示，文章的RAG管道由三个阶段组成:知识构建、知识检索和自适应上下文学习(ICL)</p>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714153955130.png" class="" title="image-20240714153955130">
<ul>
<li>知识构建：这是知识检索的第一阶段，涉及将来自不同来源的文档（如PDF文件、网页等）转换为中间表示形式，并将它们存储在结构化的知识库中。<ul>
<li>知识库K是来自各种文档的集合，从$d_1^{loc},…,d_N^{loc}$，将每个文档$d_n$分为多个段落$p_{n,1}^{loc},…,p_{n,M_n}^{loc}$其中$M_n$表示第$n$个文档的段落索引，并通过一个编码器将$f_key$每个段落嵌入到多维嵌入$e_{n,m}^{loc}$​​中。然后，DB-GPT除了采用现有的基于向量的知识表示，还采用了倒排索引和图形索引技术，以便于准确地找到与上下文相关的数据</li>
</ul>
</li>
<li>知识检索：当用户提出一个语言查询时，<strong>系统会将查询嵌入到一个向量中，然后从知识库中检索与查询最相关的K个段落</strong>。检索方法可以基于余弦相似度或其他关键词匹配技术。<ul>
<li>当语言查询$x$出现时，它通过一个<strong>编码器$f_{query}$嵌入到向量</strong>中，然后我们从知识库当中<strong>检索前K个相关的段落</strong>，其中K是一个超参数。DG-GPT支持多种检索器模型，如Embeddingretrierver，它根据余弦相似度进行检索（$q^Te/||q|||e||$​​）Keywordretriiever，它匹配<strong>关键字</strong>而不是整个句子。</li>
</ul>
</li>
<li>学习嵌入和搜索：在这个阶段，系统通过训练编码器（encoders）来优化查询和文档段落的嵌入表示，使得相关性强的查询-段落对具有较高的相似度得分。<ul>
<li>自信地认为一个更高的相似度表示更相关的段落是因为训练了编码器$f_{key}$和$f_{query}$。他们在3.2进行优化了。直觉上，我们想要点积$q^Te$​对于查询段对来说是相对较大的，因为它们是相关的。编码器使用<strong>Multilingual-E5-base model</strong><ul>
<li>Multilingual-E5-base 是一种多语言嵌入模型，属于 Hugging Face 及其社区发布的语言模型系列之一。该模型基于跨语言嵌入技术，能够处理和生成多种语言的文本表示。</li>
</ul>
</li>
</ul>
</li>
<li><p>自适应ICL与LLM生成：在检索到相关段落后，系统使用自适应上下文学习方法来生成响应。这涉及到根据检索结果的相似度对它们进行排序，然后将最相关的几个结果插入到预定义的提示模板的上下文部分，最后由大型语言模型（LLM）生成回答。</p>
<ul>
<li>自适应上下文学习方法（Adaptive Context Learning，ACL）是一种动态调整和优化上下文内容以提高大语言模型（LLM）生成回答准确性和相关性的方法。在自适应上下文学习方法中，系统会根据检索到的相关段落，<strong>按照一定的策略和标准对其进行筛选和排序，将最相关的段落插入到预定义的提示模板中</strong>，从而为LLM提供最佳的上下文信息。</li>
<li><p>示例：</p>
<ul>
<li><p>假设有一个查询 “什么是机器学习？”，系统在知识库中检索到以下段落：</p>
<ul>
<li>段落A：机器学习是一种人工智能的分支，旨在通过经验和数据进行学习和改进。</li>
<li>段落B：深度学习是机器学习的一个子领域，它使用神经网络进行数据处理。</li>
<li>段落C：机器学习包括监督学习、无监督学习和强化学习等多种类型。</li>
</ul>
</li>
<li><p>经过排序和筛选，系统选择段落A和段落C作为最相关的上下文。然后将这些段落插入到<strong>提示模板</strong>中，如：</p>
<ul>
<li>问题：什么是机器学习？<br>上下文：<ol>
<li>机器学习是一种人工智能的分支，旨在通过经验和数据进行学习和改进。</li>
<li>机器学习包括监督学习、无监督学习和强化学习等多种类型。<br> 回答：</li>
</ol>
</li>
</ul>
</li>
<li><p>将上述提示模板输入LLM，由模型生成最终的回答，也就想要的SQL部分。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714160130046.png" class="" title="image-20240714160130046">
<h2 id="2-2-部署和推理-面向服务的多模型框架"><a href="#2-2-部署和推理-面向服务的多模型框架" class="headerlink" title="2.2 部署和推理:面向服务的多模型框架"></a>2.2 部署和推理:面向服务的多模型框架</h2><ul>
<li><p>在DB-GPT中，为了简化模型适配、提高模型部署效率和优化模型部署性能，提出了面向服务的多模型框架(SMMF)，提供了一种基于云的AI方法，使得开发者和企业能够访问预构建的、预训练的机器学习模型。这种方式简化了模型的获取和使用过程。</p>
</li>
<li><p>SMMF由两个主要部分组成</p>
<ul>
<li><strong>模型推理层</strong>，它被设计来适应各种大型语言模型（LLM）的推理平台，例如vLLM、HuggingFace Transformers、Text Generation Inference (TGI)和TensorRT等。</li>
<li><strong>模型部署层</strong>：作为底层推理层和上层模型服务功能之间的中介。它负责管理模型的元数据，并作为广泛部署架构的核心。<ul>
<li><strong>API服务器和模型处理器</strong>：在模型部署框架层中，API服务器和模型处理器提供强大的模型服务功能，供应用层使用。</li>
</ul>
</li>
<li><strong>模型控制器</strong>：模型控制器负责管理模型的元数据，并作为部署架构的中心节点。</li>
<li><strong>模型工作器</strong>：模型工作器与推理设备和基础设置建立直接连接，确保实施模型的高效性能。</li>
</ul>
</li>
</ul>
<h2 id="2-3-多代理的策略"><a href="#2-3-多代理的策略" class="headerlink" title="2.3 多代理的策略"></a>2.3 多代理的策略</h2><p>DB-GPT系统中的多代理策略旨在通过智能代理的协作和专业化，提高数据库操作的效率、灵活性和用户体验，同时保持系统的可扩展性和适应性。</p>
<p>DB-GPT为不同的数据库操作角色（如数据分析师、软件工程师和数据库架构师）分配<strong>特定的代理</strong>，每个代理都有其独特的功能和专长。通过一个协调机制，系统能够实现不同代理之间的协作，使它们能够相互通信、共享信息，并进行集体推理。</p>
<ul>
<li>就是我数据分析师，给的就是一个专门用来进行数据分析的DB-GPT</li>
</ul>
<p>DB-GPT基于Text-to-SQL调优的LLM，<strong>实现了具有高级数据库交互能力的代理的开发和应用</strong>。此外，与LlamaIndex的组件为特定用例提供更明确、约束的行为不同，DB-GPT赋予agent更强的一般推理能力，约束更少。</p>
<ul>
<li>LlamaIndex 是一个工具，用于连接大语言模型（LLM）和外部数据源，使 LLM 能够高效地访问和利用这些数据源中的信息进行任务处理。LlamaIndex 的主要功能包括数据索引、查询处理和信息检索，旨在增强 LLM 的回答能力和准确性。</li>
</ul>
<h2 id="2-4-DB插件"><a href="#2-4-DB插件" class="headerlink" title="2.4 DB插件"></a>2.4 DB插件</h2><p>DB-GPT系统中的DB插件旨在通过提供自然语言查询接口、增强LLMs的查询理解与执行能力、集成第三方服务以及支持端到端的数据分析流程，来增强系统与数据库的交互能力。这些插件允许系统更智能地解析和响应用户查询，执行SQL语句，并与外部数据源协同工作，从而提升数据库操作的效率和用户体验，同时保持系统的灵活性和可扩展性。</p>
<h1 id="3-模型和训练"><a href="#3-模型和训练" class="headerlink" title="3 模型和训练"></a>3 模型和训练</h1><h2 id="3-1-Text-to-SQL-微调"><a href="#3-1-Text-to-SQL-微调" class="headerlink" title="3.1 Text-to-SQL 微调"></a>3.1 Text-to-SQL 微调</h2><ul>
<li><p>是DB-GPT系统中使LLMs更加精准和高效地理解和生成SQL查询的关键步骤，它通过专门针对数据库查询语言的优化，提升了整个系统的数据库交互能力。</p>
</li>
<li><p>模型结构：我们从预训练的Qwen开始，该Qwen使用广泛的英语和汉语语料库进行预训练</p>
<ul>
<li>Qwen：通义千问，阿里巴巴的大语言模型</li>
</ul>
</li>
<li>数据集和训练：设计了一个特殊的模块DB-GPT- hub，它封装了预处理记录、模型加载和微调的管道。我们在Spider上微调Qwen训练分割，输入包括数据库描述和自然问题(见清单2)，输出是目标SQL。<ul>
<li>Spider 数据集是一个广泛用于研究和评估 Text-to-SQL 模型的基准数据集。该数据集由耶鲁大学的研究团队创建，旨在推动自然语言处理领域中将自然语言查询转换为 SQL 查询的研究和进展。<ul>
<li><strong>多样性</strong>：数据集中包含了来自不同领域的多个数据库，涵盖广泛的主题和结构。每个数据库都有不同的表和关系，提供了丰富多样的查询场景。</li>
<li><strong>复杂性</strong>：Spider 数据集中的查询从简单到复杂不等，涵盖了基础的单表查询、复杂的多表联接查询、嵌套查询等。这使得它对模型的语义理解和生成能力提出了较高的要求。</li>
<li><strong>语义丰富</strong>：自然语言查询包含丰富的语义信息，需要模型能够正确理解查询意图和细节。</li>
<li><strong>SQL 多样性</strong>：数据集中的 SQL 查询语句多样，涵盖了不同类型的 SQL 操作和函数，要求模型具备生成多种 SQL 结构的能力。</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714200312684.png" class="" title="image-20240714200312684">
<ul>
<li>关于文本到sql的微调llm的架构和评估的全部细节可以在我们即将发布的另一篇论文中找到。</li>
</ul>
<h2 id="3-2-Encoder-in-RAG"><a href="#3-2-Encoder-in-RAG" class="headerlink" title="3.2 Encoder in RAG"></a>3.2 Encoder in RAG</h2><p>Encoder in RAG是实现高效、准确问答功能的基础，它通过将自然语言查询转换为向量表示，并与知识库中的文档进行匹配，从而检索出最相关的信息，为生成准确的回答提供支持。</p>
<ul>
<li>模型架构：键和查询编码器$f_{key}$和$f_{query}$被初始化为Multilingual-E5-base模型结构因为我们支持双语的应用<ul>
<li>他们优化的目标函数如下：</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\ell=\mathbf{q}^\top\mathbf{e}_0-\log\sum_{i=0}^I\exp\left(\mathbf{q}^\top\mathbf{e}_i\right),</script><ul>
<li><p>其中，$e_0$是已知包含查询相关信息的段落的嵌入，以及其他$I$个嵌入$e_1,…,e_I$属于一组消极段落（模块3.2有说明他们是如何被选择的）。通过优化这个灯饰，对实际相关的查询段落对，点积$q^T$和$e$​​的值会变大</p>
<ul>
<li>这些消极段落是在训练RAG模型的编码器时使用的，用于区分和优化模型对相关段落的选择能力，下面有提到<strong>从整个段落池中随机抽取5个消极的响应</strong>的选取方法</li>
</ul>
</li>
<li><p>数据集和训练：我们使用查询-段落对来训练键和查询编码器，$f_{key}$和$f_{query}$​​，这些对是从DatabaseQA中收集的，我们对1000个查询-响应对进行采样，作为积极的对，对于每一个对，我们<strong>从整个段落池中随机抽取5个消极的响应</strong>。最后，我们收集了1000对查询-响应对用于训练和评估。然后将选择的配对分成700对训练配对、100对发展配对和200对测试配对。</p>
<ul>
<li><p>大概的代码流程：</p>
<ul>
<li><p>假设我们有以下查询-响应数据集</p>
<p>假设我们有一个包含1000个查询-响应对的初始数据集：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例数据</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;query&#x27;</span>: [<span class="string">f&#x27;query_<span class="subst">&#123;i&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1001</span>)],</span><br><span class="line">    <span class="string">&#x27;response&#x27;</span>: [<span class="string">f&#x27;response_<span class="subst">&#123;i&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1001</span>)]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataFrame</span></span><br><span class="line">df = pd.DataFrame(data)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>采样消极响应</p>
<p>接下来，我们为每个查询-响应对随机采样5个消极响应：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 采样消极响应</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_negative_responses</span>(<span class="params">df, num_negatives=<span class="number">5</span></span>):</span><br><span class="line">    queries = df[<span class="string">&#x27;query&#x27;</span>].tolist()</span><br><span class="line">    responses = df[<span class="string">&#x27;response&#x27;</span>].tolist()</span><br><span class="line">    negative_samples = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> query, response <span class="keyword">in</span> <span class="built_in">zip</span>(queries, responses):</span><br><span class="line">        <span class="comment"># 从所有响应中排除正确的响应</span></span><br><span class="line">        negative_pool = [resp <span class="keyword">for</span> resp <span class="keyword">in</span> responses <span class="keyword">if</span> resp != response]</span><br><span class="line">        <span class="comment"># 随机抽取5个消极响应</span></span><br><span class="line">        negative_responses = random.sample(negative_pool, num_negatives)</span><br><span class="line">        <span class="keyword">for</span> neg_response <span class="keyword">in</span> negative_responses:</span><br><span class="line">            negative_samples.append(&#123;<span class="string">&#x27;query&#x27;</span>: query, <span class="string">&#x27;response&#x27;</span>: neg_response, <span class="string">&#x27;label&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> negative_samples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取消极响应对</span></span><br><span class="line">negative_samples = sample_negative_responses(df)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>创建训练、发展和测试数据集</p>
<p>我们将原始的1000个积极对和生成的5000个消极对混合在一起，并将它们分成训练、发展和测试数据集：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建积极响应对并标注</span></span><br><span class="line">positive_samples = [&#123;<span class="string">&#x27;query&#x27;</span>: row[<span class="string">&#x27;query&#x27;</span>], <span class="string">&#x27;response&#x27;</span>: row[<span class="string">&#x27;response&#x27;</span>], <span class="string">&#x27;label&#x27;</span>: <span class="number">1</span>&#125; <span class="keyword">for</span> _, row <span class="keyword">in</span> df.iterrows()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并积极和消极响应对</span></span><br><span class="line">all_samples = positive_samples + negative_samples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打乱所有样本</span></span><br><span class="line">random.shuffle(all_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataFrame</span></span><br><span class="line">all_samples_df = pd.DataFrame(all_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集</span></span><br><span class="line">train_size = <span class="number">700</span></span><br><span class="line">dev_size = <span class="number">100</span></span><br><span class="line">test_size = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">train_df = all_samples_df.iloc[:train_size]</span><br><span class="line">dev_df = all_samples_df.iloc[train_size:train_size + dev_size]</span><br><span class="line">test_df = all_samples_df.iloc[train_size + dev_size:train_size + dev_size + test_size]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集大小: <span class="subst">&#123;<span class="built_in">len</span>(train_df)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;发展集大小: <span class="subst">&#123;<span class="built_in">len</span>(dev_df)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集大小: <span class="subst">&#123;<span class="built_in">len</span>(test_df)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>我们将查询-响应对传递给模型，以产生每个对的标量分数，并最大化正对的分数，同时通过交叉熵损失最小化负对的分数。</p>
</li>
</ul>
<h2 id="3-3-应用和部署细节"><a href="#3-3-应用和部署细节" class="headerlink" title="3.3 应用和部署细节"></a>3.3 应用和部署细节</h2><h1 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4 Experiments"></a>4 Experiments</h1><p>提出了旨在评估DB-GPT系统性能的实验，包括文本到sql响应的生成质量(第3.1节)、我们提出的RAG机制的QA性能(第2.1节)和SMMF的效率性能(?)。我们还提供了生成数据分析的定性结果(第2.4节)。</p>
<h2 id="4-1-Text-to-SQL-Evalution"><a href="#4-1-Text-to-SQL-Evalution" class="headerlink" title="4.1 Text-to-SQL Evalution"></a>4.1 Text-to-SQL Evalution</h2><ul>
<li><p><strong>数据集：</strong>Spider数据集</p>
</li>
<li><p><strong>指标：</strong>执行精度(EX)作为度量标准</p>
<ul>
<li>EX在一些数据库实例上将预测的SQL查询的执行输出与实际的SQL查询的执行输出进行比较。EX越高越好</li>
<li>步骤<ul>
<li><strong>执行SQL查询</strong>：将模型生成的SQL查询和真实（或基准）SQL查询分别在数据库上执行。</li>
<li><strong>获取结果集</strong>：记录两个查询的执行结果，通常是从数据库检索到的数据行或记录集。</li>
<li><strong>比较结果集</strong>：比较两个结果集，确定它们是否相同或在某种程度上相似。</li>
<li><strong>计算相似度</strong>：使用某种形式的相似度度量（例如，Jaccard相似度、精确匹配、F1分数等）来量化两个结果集之间的相似性。</li>
<li><strong>确定阈值</strong>：根据任务的具体要求，确定一个阈值来判断何时认为两个结果集是足够相似的。</li>
<li><strong>生成执行精度分数</strong>：基于比较结果和相似度度量，生成一个0到1之间的分数，表示模型生成的SQL查询的执行精度。在某些情况下，完全一致的结果集可能会得到1.0的分数，而完全不匹配的结果集可能会得到0.0的分数。</li>
<li><strong>平均执行精度</strong>：如果是在多个查询上评估模型，可能会计算所有查询的平均执行精度，以得到模型整体性能的度量。</li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714202654325.png" class="" title="image-20240714202654325">
<h2 id="4-2-RAG-Evaluation"><a href="#4-2-RAG-Evaluation" class="headerlink" title="4.2 RAG Evaluation"></a>4.2 RAG Evaluation</h2><ul>
<li><strong>数据集</strong>：构建了两个QA数据集:DatabaseQA和FinancialQA。<ul>
<li>对于DatabaseQA，我们从三个代表性数据库系统中收集了1000个pdf格式的公共教程:OceanBase、MySQL、MongoDB</li>
<li>对于FinancialQA，我们从研究机构发表的1000份文件中取样。对于每个数据集，我们构建了100个问题用于测试，其中的问题由专家标注了难度。</li>
</ul>
</li>
<li><strong>指标：</strong>有三位专家对每个回答进行评分，评分从0到5，得分越高的回答越好，并将他们的平均值作为最终得分。</li>
</ul>
<img src="/2024/07/14/DB-GPT-Empowering-Database-Interactions-with-Private-Large-Language-Models/image-20240714203229767.png" class="" title="image-20240714203229767">
<h2 id="4-3-SMMF-Evaluation"><a href="#4-3-SMMF-Evaluation" class="headerlink" title="4.3 SMMF Evaluation"></a>4.3 SMMF Evaluation</h2><ul>
<li><p><strong>数据集：</strong>测试在一台服务器上执行，在所有实验中，我们使用相同的提示符，将8个标记作为输入，同时将输出长度设置为256个标记。</p>
</li>
<li><p><strong>指标</strong>：</p>
<ul>
<li>第一个令牌延迟(FTL))：以毫秒为单位测量，它表示从DB-GPT模型部署框架接收请求到推理框架解码第一个令牌所花费的时间。</li>
<li>推断延迟(IL):以秒为单位测量，它表示从DBGPT模型部署框架接收请求到推断框架解码完整响应所花费的时间。</li>
<li>吞吐量:DB-GPT模型部署框架在所有请求中每秒处理的令牌总数。</li>
</ul>
</li>
</ul>

    </div>
    
    
    
    
    
    
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2024 XuSibo&#39;s Blog
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;Rick
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
    




    
</body>
</html>
